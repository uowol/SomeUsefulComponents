{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn \n",
    "from torch.utils.data import DataLoader     # 데이터로더는 데이터셋을 iterable하게 감싸는 역할\n",
    "from torchvision import datasets            # 데이터셋은 샘플과 정답을 저장함\n",
    "from torchvision.transforms import ToTensor\n",
    "import clip\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "image_title = 'A horse in the space.png'\n",
    "\n",
    "image = preprocess(Image.open(image_title)).unsqueeze(0).to(device)\n",
    "text = clip.tokenize(\"A A horse in the space\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-2.6264e-03,  5.0962e-05,  2.7496e-02,  ..., -1.0025e-02,\n",
       "         -1.2222e-02,  5.8403e-03],\n",
       "        [-1.9852e-02,  7.1182e-03,  8.9788e-04,  ...,  1.1528e-02,\n",
       "         -1.9485e-02, -8.0185e-03],\n",
       "        [-8.6288e-03,  1.9226e-03, -2.1725e-03,  ...,  3.9330e-03,\n",
       "         -1.1269e-02,  1.5345e-03],\n",
       "        ...,\n",
       "        [-1.1993e-02,  1.2955e-02,  2.5848e-02,  ..., -9.8038e-03,\n",
       "         -4.2076e-03,  1.5211e-04],\n",
       "        [-1.2871e-02, -9.5673e-03, -1.0826e-02,  ..., -7.0610e-03,\n",
       "         -4.3182e-03, -4.9353e-04],\n",
       "        [-4.4098e-03,  3.3588e-03, -1.2054e-02,  ...,  6.1073e-03,\n",
       "          3.9940e-03, -3.0861e-03]], device='cuda:0', dtype=torch.float16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.visual.proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 50, 768])\n",
      "torch.Size([1, 768])\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "img_embeddings = [torch.zeros([1, 512]) for i in range(model.visual.transformer.layers)]\n",
    "\n",
    "#%% model.encode_image\n",
    "\n",
    "# image -> tokens\n",
    "x = model.visual.conv1(image.type(model.visual.conv1.weight.dtype))\n",
    "x = x.reshape(x.shape[0], x.shape[1], -1)   # shape = [*, width, grid ** 2]\n",
    "x = x.permute(0, 2, 1)                      # shape = [*, grid ** 2, width]\n",
    "x = torch.cat([model.visual.class_embedding.to(x.dtype) + torch.zeros(x.shape[0], 1, x.shape[-1], dtype=x.dtype, device=x.device), x], dim=1)  # shape = [*, grid ** 2 + 1, width]\n",
    "x = x + model.visual.positional_embedding.to(x.dtype)\n",
    "x = model.visual.ln_pre(x)\n",
    "\n",
    "# tokens -> transformer -> feature_embeddings\n",
    "x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "\n",
    "for i in range(model.visual.transformer.layers):\n",
    "    x = model.visual.transformer.resblocks[i](x)\n",
    "    tmp = x.permute(1, 0, 2)\n",
    "    tmp = model.visual.ln_post(tmp[:, 0, :])\n",
    "    if model.visual.proj is not None:\n",
    "        tmp = tmp @ model.visual.proj\n",
    "    img_embeddings[i].copy_(tmp)\n",
    "\n",
    "x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "print(x.shape)  \n",
    "\n",
    "x = model.visual.ln_post(x[:, 0, :])    # [CLS] token의 임베딩을 사용\n",
    "print(x.shape)  \n",
    "\n",
    "if model.visual.proj is not None:\n",
    "    x = x @ model.visual.proj\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 77, 512])\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "txt_embeddings = [torch.zeros([1, 512]) for i in range(model.transformer.layers)]\n",
    "\n",
    "#%% model.encode_image\n",
    "\n",
    "x = model.token_embedding(text).type(model.dtype)  # [batch_size, n_ctx, d_model]\n",
    "\n",
    "x = x + model.positional_embedding.type(model.dtype)\n",
    "x = x.permute(1, 0, 2)  # NLD -> LND\n",
    "\n",
    "for i in range(model.transformer.layers):\n",
    "    x = model.transformer.resblocks[i](x)\n",
    "    tmp = x.permute(1, 0, 2)\n",
    "    tmp = model.ln_final(tmp).type(model.dtype)\n",
    "    tmp = tmp[torch.arange(tmp.shape[0]), text.argmax(dim=-1)] @ model.text_projection\n",
    "    txt_embeddings[i].copy_(tmp)\n",
    "\n",
    "\n",
    "x = x.permute(1, 0, 2)  # LND -> NLD\n",
    "x = model.ln_final(x).type(model.dtype)\n",
    "print(x.shape)\n",
    "\n",
    "x = x[torch.arange(x.shape[0]), text.argmax(dim=-1)] @ model.text_projection    \n",
    "    # x.shape[0] : 들어온 단어 토큰의 개수\n",
    "    # x[[(which_word_token)], (which_end_token)] : [CLS] token이 아니라 end token의 임베딩을 사용\n",
    "    # text.argmax(dim=-1) : end token의 위치\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img_embeddings), len(txt_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7.615795612335205,\n",
       "  9.797560691833496,\n",
       "  11.156327247619629,\n",
       "  9.027064323425293,\n",
       "  6.2413458824157715,\n",
       "  6.277929782867432,\n",
       "  11.906933784484863,\n",
       "  15.012986183166504,\n",
       "  14.751118659973145,\n",
       "  16.606121063232422,\n",
       "  15.018819808959961,\n",
       "  24.93141746520996],\n",
       " [6.330994129180908,\n",
       "  8.5187406539917,\n",
       "  9.775116920471191,\n",
       "  7.487305641174316,\n",
       "  4.8748860359191895,\n",
       "  4.953120231628418,\n",
       "  10.725042343139648,\n",
       "  13.944134712219238,\n",
       "  13.571572303771973,\n",
       "  15.294862747192383,\n",
       "  13.928719520568848,\n",
       "  23.036231994628906],\n",
       " [6.784273147583008,\n",
       "  8.728285789489746,\n",
       "  10.201212882995605,\n",
       "  7.814774036407471,\n",
       "  5.212159633636475,\n",
       "  5.04819917678833,\n",
       "  10.780756950378418,\n",
       "  14.003941535949707,\n",
       "  13.499654769897461,\n",
       "  15.335693359375,\n",
       "  13.966981887817383,\n",
       "  23.18608856201172],\n",
       " [7.7387003898620605,\n",
       "  9.74960708618164,\n",
       "  11.19079303741455,\n",
       "  8.873252868652344,\n",
       "  6.261541366577148,\n",
       "  6.105512619018555,\n",
       "  11.513084411621094,\n",
       "  14.71274471282959,\n",
       "  14.375870704650879,\n",
       "  16.073898315429688,\n",
       "  14.695353507995605,\n",
       "  23.77459144592285],\n",
       " [8.214287757873535,\n",
       "  9.829022407531738,\n",
       "  11.209044456481934,\n",
       "  9.299650192260742,\n",
       "  6.78659200668335,\n",
       "  6.532819747924805,\n",
       "  12.018381118774414,\n",
       "  15.231709480285645,\n",
       "  14.899362564086914,\n",
       "  16.453754425048828,\n",
       "  15.434645652770996,\n",
       "  24.47608184814453],\n",
       " [8.431873321533203,\n",
       "  9.94196605682373,\n",
       "  10.736769676208496,\n",
       "  8.945768356323242,\n",
       "  6.3149003982543945,\n",
       "  6.281411170959473,\n",
       "  12.005577087402344,\n",
       "  15.299394607543945,\n",
       "  14.877792358398438,\n",
       "  16.792184829711914,\n",
       "  15.93602180480957,\n",
       "  24.548994064331055],\n",
       " [8.650493621826172,\n",
       "  10.241815567016602,\n",
       "  11.223325729370117,\n",
       "  9.289751052856445,\n",
       "  6.665460109710693,\n",
       "  6.895752429962158,\n",
       "  12.61672592163086,\n",
       "  15.955805778503418,\n",
       "  15.814282417297363,\n",
       "  17.654569625854492,\n",
       "  16.05727767944336,\n",
       "  25.066469192504883],\n",
       " [8.574219703674316,\n",
       "  10.119183540344238,\n",
       "  10.903237342834473,\n",
       "  8.73231315612793,\n",
       "  5.785589218139648,\n",
       "  5.9142351150512695,\n",
       "  11.383699417114258,\n",
       "  14.899574279785156,\n",
       "  14.854155540466309,\n",
       "  16.726036071777344,\n",
       "  15.207499504089355,\n",
       "  23.65328025817871],\n",
       " [9.553253173828125,\n",
       "  10.961342811584473,\n",
       "  11.61048698425293,\n",
       "  9.479312896728516,\n",
       "  6.388657569885254,\n",
       "  6.571413993835449,\n",
       "  12.33612060546875,\n",
       "  15.380189895629883,\n",
       "  15.221705436706543,\n",
       "  17.303176879882812,\n",
       "  15.535469055175781,\n",
       "  23.52182960510254],\n",
       " [9.85700511932373,\n",
       "  11.301011085510254,\n",
       "  12.231568336486816,\n",
       "  10.547597885131836,\n",
       "  7.134830951690674,\n",
       "  6.870478630065918,\n",
       "  12.296224594116211,\n",
       "  15.458337783813477,\n",
       "  15.61960506439209,\n",
       "  17.44537353515625,\n",
       "  16.084753036499023,\n",
       "  24.610097885131836],\n",
       " [10.145522117614746,\n",
       "  11.80378532409668,\n",
       "  12.988690376281738,\n",
       "  11.532842636108398,\n",
       "  8.82828426361084,\n",
       "  8.41851806640625,\n",
       "  14.015678405761719,\n",
       "  17.51683235168457,\n",
       "  18.025867462158203,\n",
       "  19.151390075683594,\n",
       "  20.249164581298828,\n",
       "  29.979433059692383],\n",
       " [13.722640037536621,\n",
       "  15.046772956848145,\n",
       "  14.040470123291016,\n",
       "  14.182207107543945,\n",
       "  13.925982475280762,\n",
       "  13.612883567810059,\n",
       "  16.09810447692871,\n",
       "  19.198366165161133,\n",
       "  21.571008682250977,\n",
       "  19.921899795532227,\n",
       "  26.939844131469727,\n",
       "  34.29296875]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_similarity_by_layer = [[(img_embeddings[i] @ txt_embeddings[j].T).item() for j in range(12)] for i in range(12)]\n",
    "img_similarity_by_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7.615795612335205,\n",
       "  6.330994129180908,\n",
       "  6.784273147583008,\n",
       "  7.7387003898620605,\n",
       "  8.214287757873535,\n",
       "  8.431873321533203,\n",
       "  8.650493621826172,\n",
       "  8.574219703674316,\n",
       "  9.553253173828125,\n",
       "  9.85700511932373,\n",
       "  10.145522117614746,\n",
       "  13.722640037536621],\n",
       " [9.797560691833496,\n",
       "  8.5187406539917,\n",
       "  8.728285789489746,\n",
       "  9.74960708618164,\n",
       "  9.829022407531738,\n",
       "  9.94196605682373,\n",
       "  10.241815567016602,\n",
       "  10.119183540344238,\n",
       "  10.961342811584473,\n",
       "  11.301011085510254,\n",
       "  11.80378532409668,\n",
       "  15.046772956848145],\n",
       " [11.156327247619629,\n",
       "  9.775116920471191,\n",
       "  10.201212882995605,\n",
       "  11.19079303741455,\n",
       "  11.209044456481934,\n",
       "  10.736769676208496,\n",
       "  11.223325729370117,\n",
       "  10.903237342834473,\n",
       "  11.61048698425293,\n",
       "  12.231568336486816,\n",
       "  12.988690376281738,\n",
       "  14.040470123291016],\n",
       " [9.027064323425293,\n",
       "  7.487305641174316,\n",
       "  7.814774036407471,\n",
       "  8.873252868652344,\n",
       "  9.299650192260742,\n",
       "  8.945768356323242,\n",
       "  9.289751052856445,\n",
       "  8.73231315612793,\n",
       "  9.479312896728516,\n",
       "  10.547597885131836,\n",
       "  11.532842636108398,\n",
       "  14.182207107543945],\n",
       " [6.2413458824157715,\n",
       "  4.8748860359191895,\n",
       "  5.212159633636475,\n",
       "  6.261541366577148,\n",
       "  6.78659200668335,\n",
       "  6.3149003982543945,\n",
       "  6.665460109710693,\n",
       "  5.785589218139648,\n",
       "  6.388657569885254,\n",
       "  7.134830951690674,\n",
       "  8.82828426361084,\n",
       "  13.925982475280762],\n",
       " [6.277929782867432,\n",
       "  4.953120231628418,\n",
       "  5.04819917678833,\n",
       "  6.105512619018555,\n",
       "  6.532819747924805,\n",
       "  6.281411170959473,\n",
       "  6.895752429962158,\n",
       "  5.9142351150512695,\n",
       "  6.571413993835449,\n",
       "  6.870478630065918,\n",
       "  8.41851806640625,\n",
       "  13.612883567810059],\n",
       " [11.906933784484863,\n",
       "  10.725042343139648,\n",
       "  10.780756950378418,\n",
       "  11.513084411621094,\n",
       "  12.018381118774414,\n",
       "  12.005577087402344,\n",
       "  12.61672592163086,\n",
       "  11.383699417114258,\n",
       "  12.33612060546875,\n",
       "  12.296224594116211,\n",
       "  14.015678405761719,\n",
       "  16.09810447692871],\n",
       " [15.012986183166504,\n",
       "  13.944134712219238,\n",
       "  14.003941535949707,\n",
       "  14.71274471282959,\n",
       "  15.231709480285645,\n",
       "  15.299394607543945,\n",
       "  15.955805778503418,\n",
       "  14.899574279785156,\n",
       "  15.380189895629883,\n",
       "  15.458337783813477,\n",
       "  17.51683235168457,\n",
       "  19.198366165161133],\n",
       " [14.751118659973145,\n",
       "  13.571572303771973,\n",
       "  13.499654769897461,\n",
       "  14.375870704650879,\n",
       "  14.899362564086914,\n",
       "  14.877792358398438,\n",
       "  15.814282417297363,\n",
       "  14.854155540466309,\n",
       "  15.221705436706543,\n",
       "  15.61960506439209,\n",
       "  18.025867462158203,\n",
       "  21.571008682250977],\n",
       " [16.606121063232422,\n",
       "  15.294862747192383,\n",
       "  15.335693359375,\n",
       "  16.073898315429688,\n",
       "  16.453754425048828,\n",
       "  16.792184829711914,\n",
       "  17.654569625854492,\n",
       "  16.726036071777344,\n",
       "  17.303176879882812,\n",
       "  17.44537353515625,\n",
       "  19.151390075683594,\n",
       "  19.921899795532227],\n",
       " [15.018819808959961,\n",
       "  13.928719520568848,\n",
       "  13.966981887817383,\n",
       "  14.695353507995605,\n",
       "  15.434645652770996,\n",
       "  15.93602180480957,\n",
       "  16.05727767944336,\n",
       "  15.207499504089355,\n",
       "  15.535469055175781,\n",
       "  16.084753036499023,\n",
       "  20.249164581298828,\n",
       "  26.939844131469727],\n",
       " [24.93141746520996,\n",
       "  23.036231994628906,\n",
       "  23.18608856201172,\n",
       "  23.77459144592285,\n",
       "  24.47608184814453,\n",
       "  24.548994064331055,\n",
       "  25.066469192504883,\n",
       "  23.65328025817871,\n",
       "  23.52182960510254,\n",
       "  24.610097885131836,\n",
       "  29.979433059692383,\n",
       "  34.29296875]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_similarity_by_layer = [[(txt_embeddings[i] @ img_embeddings[j].T).item() for j in range(12)] for i in range(12)]\n",
    "txt_similarity_by_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08, 0.07, 0.07, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.08, 0.1, 0.12]\n",
      "[0.06, 0.07, 0.07, 0.06, 0.04, 0.04, 0.08, 0.1, 0.1, 0.11, 0.11, 0.16]\n"
     ]
    }
   ],
   "source": [
    "img_sum_similarity_by_layer = [sum(x) for x in img_similarity_by_layer]\n",
    "txt_sum_similarity_by_layer = [sum(x) for x in txt_similarity_by_layer]\n",
    "print([round(x/sum(img_sum_similarity_by_layer), 2) for x in img_sum_similarity_by_layer])\n",
    "print([round(x/sum(txt_sum_similarity_by_layer), 2) for x in txt_sum_similarity_by_layer])\n",
    "# 이 결과값을 각 레이어에 대한 가중치로 준다면 어떨까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e13486f50ad8491adee3900c65648710623e910042c80717865a7ec3732c806"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
